---
title: "Homework_3"
author: "Cameron Zabriskie"
date: "March 31, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning=FALSE)
```


1. *In a typical bootstrap sample approximately 37% of the observations that are in the original dataset do not occur in the bootstrap sample. Here's a derivation of that result. Consider a dataset with n observations which we may label 1, 2,...,k-1, k, k+1,...,n-1,n.*
    a) *Suppose I select n observations from the original dataset with replacement. What is the chance that observation k is not among the selected observations? (Another way to think about this question is the following. Suppose I have a fair n-sided die with sides labeled 1,2,...,k,...,n. I roll the die n times-and the rolls are all independent. What is the chance that the side labeled k does not occur in the n rolls?)*
\newline
   
        If I have an n-sided die, for each roll the probability of not rolling a k is $\frac{n - 1}{n}$. Now, if each subsequent roll is independent of the prior rolls, the probability of not getting k after n rolls would be $(\frac{n - 1}{n})^n$.
\newline
    b) *Evaluate the expression you obtained in part a) for an increasing sequence of values of n.*

        If f(n) = $(\frac{n - 1}{n})^n$ then
        
```{r echo=FALSE,  comment=NA}
oobProb <- function(n){
  ((n-1) / n)^n
}

for(x in c(10, 100, 1000, 10000, 100000, 1000000)){
  print(paste0('f(',x,') = ',round(oobProb(x), 4)))
}
```

  c) *Do you recognize the limit as n approaches infinity of the expression in part a)? If so, identify and evaluate it. If not, compute the expression in part a) for some very large values of n.*

    
    In part b, I can  see that as I increase the value for n, the result will approach 0.37. I can prove this by taking the limit of this function as n approaches infinity.
    
    $$\lim_{n \to \infty} (\frac{n - 1}{n})^n = \lim_{n \to \infty} e^{\frac{ln\frac{n-1}{n}}{\frac{1}{n}}} \text{L'Hospital's rule} \lim_{n \to \infty} e ^ {\frac{\frac{1}{n(n-1)}}{\frac{-1}{n^2}}} = \lim_{n \to \infty} e^{\frac{-n}{n-1}} = e^{-1} = \frac{1}{e} \approx 0.37$$

  d) *(Quite hard) What is the standard error of the observed number and proportion of observations in the original sample that are not in a boostrap sample?*

    The probability of not choosing an observation for the bootstrap sample $(I_k = 1)$ is equal to 0.37, as shown in the previous questions. Since an observation is either picked or not picked we can treat it as a Bernoulli distribution with a variance
    
    $$Var(I_k) = Var(0.37 * (1 - 0.37)) = 0.2331$$
    
    The standard error of $I_k$ is equal to the square root of the variance.
    
    $$STDERR(I_k) = \sqrt{Var(I_k)} = \sqrt{0.2331} = 0.483$$
    
    When picking all of the observations in a bootstrap sample, since all of the samples are picked independently, the expected value of the number of distinct observations picked is equal to n * 0.37. The variance of any distribution can be defined as
    
    $$\sum_{k = 1}^{n}Var(I_k) + 2\sum_{k =1}^n\sum_{j = 1 (j \neq k)}^ncov(I_j, I_k)$$
    
    However, since each sample is drawn independently, the covariance is equal to zero, and the variance can be explained by
    
    $$\sum_{k = 1}^nVar(I_k) = np(1 - p) = n * 0.37 * (1 - 0.37) = 0.233n$$
    
    The standard error can then be calculated as
    
    $$\sqrt{\sum_{k = 1}^nVar(I_k)} = \sqrt(0.233n)$$
    
2. *This is a continuation of the analyses on the data for three bird species-(Northern) Flicker, (Mountain) Chickadee, and (Red-naped) Sapsucker-plus a bunch of sites at which none of these species of birds are nesting. In the previous homework you analyzed these data using logistic regression and LDA/QDA; in this homework I would like you to apply classification trees to the data. The first priority is to come up with accurate classifications of the nest sites, the second priority is to determine important variables to the birds in selecting nest sites, and the third priority is to determine whether the three species can be treated as one species (with regard to selection of bird nest sites) or need to be treated separately.*

    a) *First, fit a classification tree to all the data treating the three birds as a single species. Compute the accuracy of your classification using 10-fold cross-validation, and compare it with cross-validated accuracy rates for LDA, QDA, and logistic regression that you computed before.*

        I first made a unpruned tree. I then plotted the cp values to see what tree size had the minimum cp value and the cp value that corresponded to the 1-SE rule (see below).

```{r echo=FALSE, results='hide'}
library(dplyr)
library(rpart)
library(stat5810tools)
set.seed(52)
```

```{r echo=FALSE}
nest <- read.csv('Nest.csv')
nest$Nest <- as.factor(nest$Nest)
nest$StandType <- as.factor(nest$StandType)
form <- as.formula(paste0('Nest ~ ', paste(names(nest)[3:length(names(nest))], collapse = '+')))

nest.rpartFull <- rpart(form , method = 'class', 
                        data = nest, 
                        control = rpart.control(cp = 0.0, 
                                                minsplit = 2))

# plot(nest.rpartFull,margin=0.1)
plotcp(nest.rpartFull)

```

In this case, the 1SE rule supplied a cp value of 0.021, so I refit my tree with 8 leaf nodes (see tree below).

```{r echo=FALSE}

nest.rpartFull <- rpart(form , method = 'class', 
                        data = nest, 
                        control = rpart.control(cp = 0.021, 
                                                minsplit = 2))

plot(nest.rpartFull, margin=0.1)
text(nest.rpartFull, use.n=TRUE)
```

I then used 10-fold cross validation on the tree that was constructed. A confusion matrix of the results of the classification as well as the percent correctly classified, specificity, sensitivity, kappa, and AUC are shown in the tables below.

```{r echo=FALSE}
nest.xval=rep(0,nrow(nest))
xvs=rep(1:10,length=nrow(nest))
xvs=sample(xvs)

for(i in 1:10){
  test=nest[xvs==i,]
  train=nest[xvs!=i,]
  glub=rpart(form,
             control=rpart.control(cp=0.021, minsplit=2),
             data=train)
  nest.xval[xvs==i] = predict(glub,test, type = 'class')
  }

kable(table(nest$Nest, nest.xval))
kable(class.sum(as.numeric(as.character(nest$Nest)), 
          as.numeric(as.character(nest.xval))))
```

The percent correctly classified for the classification tree with 8 leaf nodes was 80.75%. LDA had a percent correctly classified of 79.34%, QDA had a percent correctly classified of 81.70% and logistic regression had a percent correctly classified of 80.8%. It looks like the classification trees did a just a little worse than QDA, performed just as well as logistic regression, and did better than LDA. However, the difference between the percent correctly classified in all of the methods is so small I would say they all performed about the same.

  b) *Fit classification trees for each bird species separately and, again, compute estimates of the accuracies by 10-fold cross validation. Qualitatively compare the classification trees for the three species*

    A tree was first fit for only the Chickadee species. A full tree was grown and, since there was no smaller tree than the minimum cp value of 0.034 (see below), I used this cp value which had an associated tree size of 8 leaf nodes.

```{r echo=FALSE}
chickadee <- nest %>% filter(Species == 'Chickadee' | Species == 'Non-nest')
form <- as.formula(paste0('Nest ~ ', paste(names(nest)[3:length(names(nest))], collapse = '+')))

nest.rpart <- rpart(form , method = 'class', 
                        data = chickadee, 
                        control = rpart.control(cp = 0.0, 
                                                minsplit = 2))


#plot(nest.rpart,margin=0.1)
plotcp(nest.rpart)
#printcp(nest.rpart)
```

The pruned tree can be seen below.

```{r echo=FALSE}
nest.rpart <- rpart(form , method = 'class', 
                    data = chickadee, 
                    control = rpart.control(cp = 0.032, 
                                            minsplit = 2))

plot(nest.rpart, margin=0.1)
text(nest.rpart, use.n=TRUE)
```

The cross validated percent correctly classified for this tree with only the Chickadee species and non-nest sites was 72.97% (see below).

```{r, echo=FALSE}
nest.xval=rep(0,nrow(chickadee))
xvs=rep(1:10,length=nrow(chickadee))
xvs=sample(xvs)

for(i in 1:10){
  test=chickadee[xvs==i,]
  train=chickadee[xvs!=i,]
  glub=rpart(form,
             control=rpart.control(cp=0.021, minsplit=2),
             data=train)
  nest.xval[xvs==i] = predict(glub,test,type="class")
  }

kable(table(chickadee$Nest, nest.xval))
```

```{r echo=FALSE}
kable(class.sum(as.numeric(as.character(chickadee$Nest)), 
          as.numeric(as.character(nest.xval))))
```

I then fit a tree for just the Flicker species. I fit a full tree and looked at the cp values to know where to prune the tree. I found that the minimum cp was at 0.1, and there were no trees smaller than it within 1SE. (see below). 

```{r echo=FALSE}
flicker <- nest %>% filter(Species == 'Flicker' | Species == 'Non-nest')
form <- as.formula(paste0('Nest ~ ', paste(names(nest)[3:length(names(nest))], collapse = '+')))

nest.rpart <- rpart(form , method = 'class', 
                        data = flicker, 
                        control = rpart.control(cp = 0.0, 
                                                minsplit = 2))


# plot(nest.rpart,margin=0.1)
plotcp(nest.rpart)
```

I used a cp value of 0.1 to build the tree shown below with 4 leaf nodes. 


```{r echo=FALSE}
nest.rpart <- rpart(form , method = 'class', 
                    data = flicker, 
                    control = rpart.control(cp = 0.1, 
                                            minsplit = 2))

plot(nest.rpart, margin=0.1)
text(nest.rpart, use.n=TRUE)
```

The cross validated percent correctly classified for the Flicker species was 86.82% (see below).
        
```{r echo=FALSE}
nest.xval=rep(0,nrow(flicker))
xvs=rep(1:10,length=nrow(flicker))
xvs=sample(xvs)

for(i in 1:10){
  test=flicker[xvs==i,]
  train=flicker[xvs!=i,]
  glub=rpart(form,
             control=rpart.control(cp=0.021, minsplit=2),
             data=train)
  nest.xval[xvs==i] = predict(glub,test,type="class")
  }

kable(table(flicker$Nest, nest.xval))
kable(class.sum(as.numeric(as.character(flicker$Nest)), 
          as.numeric(as.character(nest.xval))))
```

I finally fit a tree for just the Sapsucker species. I fit a tree and looked at the cross validated error to know where to prune the tree. I found that minimum cross validated error came from a cp value of 0.23. This corresponded to a tree size of 2 leaf nodes.

```{r echo=FALSE}
sapsucker <- nest %>% filter(Species == 'Sapsucker' | Species == 'Non-nest')
form <- as.formula(paste0('Nest ~ ', paste(names(nest)[3:length(names(nest))], collapse = '+')))

nest.rpart <- rpart(form , method = 'class', 
                        data = sapsucker, 
                        control = rpart.control(cp = 0.0, 
                                                minsplit = 2))


# plot(nest.rpart,margin=0.1)
plotcp(nest.rpart)
```

The 2 leaf tree for the Sapsucker species is shown below.

```{r echo=FALSE}
nest.rpart <- rpart(form , method = 'class', 
                    data = sapsucker, 
                    control = rpart.control(cp = 0.23, 
                                            minsplit = 2))

plot(nest.rpart, margin=0.1)
text(nest.rpart, use.n=TRUE)
```

The cross validated percent correctly classified for the Sapsucker species was 82.43% (see below).

```{r echo=FALSE}
nest.xval=rep(0,nrow(sapsucker))
xvs=rep(1:10,length=nrow(sapsucker))
xvs=sample(xvs)

for(i in 1:10){
  test=sapsucker[xvs==i,]
  train=sapsucker[xvs!=i,]
  glub=rpart(form,
             control=rpart.control(cp=0.23, minsplit=2),
             data=train)
  nest.xval[xvs==i] = predict(glub,test,type="class")
  }

kable(table(sapsucker$Nest, nest.xval))
kable(class.sum(as.numeric(as.character(sapsucker$Nest)), 
          as.numeric(as.character(nest.xval))))
```

After fitting trees that predicted nest and non-nest sites for each of the three species individually, I saw that the Flicker species had the highest percent correctly classified with 86.82%, the Sapsucker species had the next highest percent correctly classified nest and non-nest sites with 82.43%, and the Chickadee species had the lowest percent correctly classified with 72.97%.

b) Another way to get at the issue of the similarity of the bird species might be to do the following: 
    1. Fit a classification tree to the combined data using Species as the response variable.
    2. Look at the cross-validated confusion matrix for the classification tree to see where the misclassifications are occurring.
  
I fit a tree and found the minimum cp value was at a tree size of 19, but the 1 SE rule selects a tree of only 2 nodes. I cannot use the 1Se rule for this, since there are 4 species to classify, so I will go with the smallest tree within the standard error rule that has at least 4 leaf nodes, which is a tree size of 5 nodes with a corresponding cp value of 0.032.  

```{r echo=FALSE}
form <- as.formula(paste0('Species ~ ', paste(names(nest)[3:length(names(nest))], collapse = '+')))

nest.rpartFull <- rpart(form , method = 'class', 
                        data = nest, 
                        control = rpart.control(cp = 0.0, 
                                                minsplit = 2))

# plot(nest.rpartFull,margin=0.1)
plotcp(nest.rpartFull)
# printcp(nest.rpartFull)
```

From the tree shown below, we can see that all three species show up a lot in the numTree1to3in < 0.5 spit. There are only 10 non-nest sites in this node, but 22 Chickadees, 11 Flickers, and 30 Sapsuckers, show up in this leaf node. The cross validated error rates shown in the table below show that none of the Chickadees are correctly classified, only 2 of the Flicker's are correctly classified, and that 21 of the Sapsuckers are correctly classified. The classifier that the tree seems to pick the most for Chickadee is non-nest, with 21 incorrectly classified, but 18 are misclassified as Sapsucker, and the Flicker's had 13 misclassified observations as Sapsucker.

```{r echo=FALSE}
nest.rpartFull <- rpart(form , method = 'class', 
                        data = nest, 
                        control = rpart.control(cp = 0.032, 
                                                minsplit = 2))

plot(nest.rpartFull,margin=0.1)
text(nest.rpartFull, use.n=TRUE)

nest.xval=rep(0,nrow(nest))
xvs=rep(1:10,length=nrow(nest))
xvs=sample(xvs)

for(i in 1:10){
  test=nest[xvs==i,]
  train=nest[xvs!=i,]
  glub=rpart(form,
             control=rpart.control(cp=0.032, minsplit=2),
             data=train)
  nest.xval[xvs==i] = predict(glub,test,type="class")
  }
```

What was seen in the tree is more explicitly shown in the confusion matrix below. We can see that all of the birds are misclassified much more than they are classified correctly. However, the non-nest sites seem to be classified correctly most of the time. This could be due to the much larger amount of observations in the non-nest category compared to the other 3 categories.

```{r echo=FALSE}
kable(table(nest$Species, nest.xval))
```

3. *This problem concerns the forensic glass data set labeled "Glass.csv" in Canvas. There are six different types of glass, coded 1-6, and nine measured variables. The first of the measured variables is the refractive index of the glass, and the remaining eight are weight percentages of eight chemical elements. The purpose of the analysis is to classify the six types of glass using the refractive index and the chemical percentages.*

    a) *Fit a classification tree to the data using the 1-SE rule or choosing a tree just a little smaller or larger than the one selected by the 1-SE rule. Briefly summarize the tree.*

    Using the 1-SE rule, I found a tree with 8 leaf nodes with a cp value of 0.027 (see below). The first split got most of the type 6 glass separated form the other variables. If the Barium percentage was less than 0.335, the tree kept splitting. However, if the Barium amount was greater than 0.335, the glass was classified as a 6. If the Aluminum is less than 1.42, the split goes to Calcium. However, if the Aluminum amount was greater than 1.42, the split would go to Magnesium. If the Calcium amount was less than 10.48, then the split goes to Refindex, but if the amount of Calcium was greater than 10.48, the glass will be classified as type 2. If the Refindex in the glass is greater than 1.517, the split will go to Magnesium, but if the Refindex was less than 1.517, the glass will be classified as type 3. If the split at Magnesium is less than 3.865, the glass will be classified as type 1; if the Magnesium is greater than or equal to 3.865, then the glass will be classified as type 2 glass. Back to the Magnesium split after Aluminum,. If the Magnesium is greater than or equal to 2.26, the glass will be classified as type 2. However, if the Magnesium is less than 2.26, the split will go to Sodium. If the Sodium amount is less than 13.5, the glass will be classified as type 4, but if the Sodium amount is greater than or equal to 13.5, the glass will be classified to type 5 glass.

```{r echo=FALSE}
set.seed(1523)
glass <- read.csv('Glass.csv')
glass$GlassType <- as.factor(glass$GlassType)
form <- as.formula(paste0('GlassType ~ ', paste(names(glass)[1:(length(names(glass)) - 1)], collapse = '+')))
# Find the cp value to prune the tree
rpartFull <- rpart(form , method = 'class', 
                        data = glass, 
                        control = rpart.control(cp = 0.0, 
                                                minsplit = 2))
# plot(rpartFull)
# plotcp(rpartFull)
```

```{r echo=FALSE, fig.show='hide'}
# Fit tree with pruning value
rpartFull <- rpart(form , method = 'class', 
                        data = glass, 
                        control = rpart.control(cp = 0.027, 
                                                minsplit = 2))
# pdf('Problem_3.pdf')
plot(rpartFull)
# first leaf has 62 1's second leaf has 18 2's
text(rpartFull, use.n=TRUE)
# dev.off()

```

\begin{center} 
\includegraphics[width=4in]{Problem_3.png} 
\end{center}

b) *Compute the 10-fold cross-validated confusion matrix. If you have trouble doing this, you may have to consider eliminating some types of glass or collapsing categories of glass that may be similar and have small numbers of observations.*

A confusion matrix for the 10-fold cross validation of the classification tree that was built in part (a) is shown below.

```{r echo=FALSE}
glass.xval=rep(0,nrow(glass))
xvs=rep(1:10,length=nrow(glass))
xvs=sample(xvs)

for(i in 1:10){
  test=glass[xvs==i,]
  train=glass[xvs!=i,]
  glub=rpart(form,
             control=rpart.control(cp=0.027, minsplit=2),
             data=train)
  glass.xval[xvs==i] = predict(glub,test,type="class")
  }

cm <- table(glass$GlassType, glass.xval)
pcc1 <- sum(diag(cm))/sum(sapply(cm, sum))
kable(cm)
```

The overall percent correctly classified was equal to `r 100 * round(pcc1, 3)`%, which isn't that good.

4. *This problem continues the analysis of the Forensic Glass data.*

    a) *Apply random forests to the data and obtain the out-of-bag confusion matrix. How well can we classify these data, and where are the major misclassifications? How do your results compare to the classification tree you fitted problem 3?*

    A confusion matrix of the out of bag results from random forest is shown below. 
```{r echo=FALSE}
library(randomForest)
set.seed(1234)
glass.rf <- randomForest(form, data = glass, importance = TRUE)

pcc2 <- sum(diag(glass.rf$confusion[, -7]))/ sum(sapply(glass.rf$confusion[, -7], sum)) 
kable(glass.rf$confusion)
```

The random forest classified the types of glass with a percent correctly classified of `r 100 * round(pcc2, 3)`%. This is much better than the `r 100 * round(pcc1, 3)`% correctly classified that was achieved with a classification tree. The type 3, had the highest amount of classification error with almost 60% misclassified, followed by the type 4 glass at about a 30% classification rate. The smallest amount of misclassification occurred with the type 1 glass with about a 11% error rate. 

b) *Use random forests to select a subset of the variables (which may be all the variables!) Refit random forests with only the important variables and obtain the out-of-bag confusion matrix. Did you observe any change in predictive accuracy?*

A variable importance plot was constructed from the random forest model made in part (a) (see below).

```{r echo=FALSE}
varImpPlot(glass.rf)

# Partial dependency plots

# imp <- importance(glass.rf)
# impvar <- rownames(imp)[order(imp[, 1], decreasing=TRUE)]

# for (i in 1:6){
#   par(mfrow = c(3, 3))
#   for (j in seq_along(impvar)){
#     partialPlot(glass.rf, glass, impvar[j], which.class = i,
#                 xlab = paste0('partial dep on ', impvar[j]),
#                 ylim = c(0, 12),
#                 main = '')
#   }
#   mtext(paste0('Glass ',i), side = 3, line = -1, outer = TRUE)
# }
```

We can see that Magnesium has the largest mean decrease accuracy, and Iron has hardly any decrease in mean accuracy. The other variables all seem to moderately effect the mean decrease in accuracy. I decided to remove the Iron predictor variable from the model, and a confusion matrix of the out of bag observations is shown below.

```{r echo=FALSE}
# Form the variable importance plot we can see iron is probably not important in the model, but this is the only
# variable that seems to be apart from the rest of them.
form2 <- as.formula(paste0('GlassType ~ ', paste(names(glass)[1:(length(names(glass)) - 2)], collapse = '+')))
glass.rf2 <- randomForest(form2, data = glass)

pcc3 <- sum(diag(glass.rf2$confusion[, -7]))/ sum(sapply(glass.rf2$confusion[, -7], sum)) 
kable(glass.rf2$confusion)
```

The overall percent correctly classified for this model with the Iron predictor variable removed was `r 100 * round(pcc3, 3)`% for the out of bag observations. This is only marginally smaller than the out of bag percent correctly classified of `r 100 * round(pcc2, 3)`% that the random forest model with all the predictor variables in it had.

c) *Summarize your results for your analyses of the forensic glass data using classification trees and random forests.*

A classification tree, random forest with all the predictor variables, and a more parsimonious random forest with Iron removed were fit to the forensic glass data. The classification tree had a total percent correctly classified of `r 100 * round(pcc1, 3)`%, which is a very poor model. The random forest model with all of the predictor variables did significantly better with a total percent correctly classified of `r 100 * round(pcc2, 3)`%. However, a variable importance plot was constructed, and I found that the Iron predictor variable had almost no effect on the mean decrease in accuracy when the observations for Iron were jumbled across the observations. With this knowledge, I removed Iron from the model, and built a new, more parsimonious, random forests model which had a total percent correctly classified of `r 100 * round(pcc3, 3)`%, which is almost equivalent to the random forest model with all the predictor variables.
